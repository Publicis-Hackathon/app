# Brand Guideline ↔︎ FIBO Workflow

Two cooperating agents turn brand constraints into polished creative assets generated by the FIBO model. The **FiboAgent** is responsible for proposing and iteratively improving imagery, while the **BrandGuidelineAgent** evaluates color palette and gaze compliance until both agents agree on a final asset (`backend/agentic/workflow.py:13`, `backend/agentic/graph_builder.py:7`). This repo pairs that workflow with a Lovable/Vite frontend for reviewing the iterations.

## How the FIBO loop works
- **Bootstrap** – `FiboAgent` calls the simulated Original FIBO generator to draft a first image, optionally seeding it with a user upload (`backend/agentic/agents.py:68`).
- **Evaluate** – `BrandGuidelineAgent` aggregates palette and gaze tools to build a compliance report (`backend/agentic/agents.py:31`).
- **Improve** – When the report fails, FIBO runs the Color Palette LoRA pass to inject missing colors and align gaze before returning to evaluation (`backend/agentic/agents.py:102`).
- **Explainability** – Each cycle updates the timeline plus a reasoning bundle available through `AgenticWorkflow.get_reasoning`.

![FIBO loop diagram](images/diagram.png)

## Repository layout
- `backend/` – Python package containing the agents, workflow graph, structured prompt helpers, and example payloads.
- `lovable-frontend/` – Vite + React experience for presenting prompts, image previews, and compliance insights.
- `docker-compose.yml` – Builds and runs both services on the same Docker network (GPU reservation is already declared for the backend container).

## Prerequisites
| Component | Version | Notes |
| --- | --- | --- |
| Python | 3.11+ | Needed for the backend workflow and tests. |
| Node.js | 18+ (npm 9+/bun optional) | Required for the Vite frontend. |
| Docker & Compose | Latest | Optional but recommended for end-to-end orchestration. |
| API keys | `OPENAI_API_KEY`, `BRIA_API_KEY` | Populate `backend/env_example` values in your `.env`. |
| GPU (optional) | Nvidia | Only required if you replace the simulated FIBO generator with a real model. |

## Setup instructions
1. **Clone** the repo and, if you plan to use Docker, create the shared network once:
   ```bash
   git clone <repo-url> fibo-workflow && cd fibo-workflow
   docker network create net || true
   ```
2. **Create an `.env`** at the repo root. You can start from `backend/env_example` and append the compose variables:
   ```bash
   cp backend/env_example .env
   cat <<'EOF' >> .env
   FRONTEND_CONTAINER=lovable-frontend
   FRONTEND_PORT=5173
   FRONTEND_DEBUGGER_PORT=9320
   BACKEND_CONTAINER=fibo-backend
   VITE_BACKEND_PORT=8000
   BACKEND_DEBUGGER_PORT=5678
   EOF
   ```
3. **Backend (Python)**:
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   pip install -e backend
   ```
   - Run `python -m agentic` to sanity-check the package import.
   - `PYTHONPATH=backend` is a quick alternative when you do not want to create a virtual environment.
4. **Frontend (Vite + React)**:
   ```bash
   cd lovable-frontend
   npm install           # or bun install / pnpm install
   npm run dev           # serves on FRONTEND_PORT (default 5173)
   ```
5. **Full stack via Docker Compose** (after completing the `.env` file):
   ```bash
   docker compose up --build
   ```
   - The backend container exposes `VITE_BACKEND_PORT` for API calls and `BACKEND_DEBUGGER_PORT` for remote debugging.
   - The frontend hot-reloads when you edit files thanks to the bind mounts declared in `docker-compose.yml`.

## Run the FIBO workflow from the CLI
Use the bundled structured prompt example (`backend/agentic/examples/fibo_structured_prompt.json`) to watch the loop converge:

```bash
PYTHONPATH=backend python3 - <<'PY'
import asyncio, json, pathlib
from agentic.workflow import AgenticWorkflow

async def main():
    workflow = AgenticWorkflow()
    prompt = "Design a hero shot for the FIBO launch page"
    structured = json.loads(pathlib.Path(
        "backend/agentic/examples/fibo_structured_prompt.json"
    ).read_text())
    state = await workflow.generate_from_prompt(prompt, structured_prompt=structured)
    image = state["current_image"]
    report = state["compliance_report"]
    print("Colors:", image.colors)
    print("Gaze:", image.gaze_direction)
    print("Palette OK:", report.palette_ok, "Gaze OK:", report.gaze_ok)
    print("History:", *state["history"], sep="\n  - ")

asyncio.run(main())
PY
```

## Example output
```
Colors: ['#EA1E63', '#FFCA3A', '#151E3D', '#F5F5F5']
Gaze: stage-left
Palette OK: True Gaze OK: True
History:
  - FIBO agent produced a candidate image.
  - Brand Guideline agent evaluated the candidate.
  - FIBO agent applied the color palette LoRA.
  - Brand Guideline agent evaluated the candidate.
  - FIBO agent applied the color palette LoRA.
  - Brand Guideline agent evaluated the candidate.
  - Compliance achieved; workflow exiting.
```

This captures the expected behavior: FIBO injects the missing brand colors by the second pass and the Brand Guideline agent confirms compliance before the loop stops.

## API integration template
Embed the workflow inside your preferred framework. The snippet below shows how to expose it through FastAPI:

```python
from fastapi import FastAPI
from pydantic import BaseModel
from agentic.workflow import AgenticWorkflow
from agentic.structured_prompt import StructuredPrompt

app = FastAPI(title="FIBO Workflow API")
workflow = AgenticWorkflow()

class WorkflowRequest(BaseModel):
    prompt: str
    structured_prompt: dict | str | None = None
    config: dict | None = None
    image: dict | str | None = None

@app.post("/api/fibo/run")
async def run_workflow(payload: WorkflowRequest):
    structured = StructuredPrompt.from_obj(payload.structured_prompt)
    state = await workflow.generate_from_prompt(
        payload.prompt,
        structured_prompt=structured,
        config=payload.config,
        image=payload.image,
    )
    return {
        "image": state["current_image"].__dict__,
        "compliance": state["compliance_report"].__dict__,
        "history": state["history"],
        "thread_id": workflow.get_last_thread_id(),
    }
```

Tips:
- Convert dataclasses (`ImageArtifact`, `ComplianceReport`) to dictionaries before returning them over HTTP.
- Call `workflow.get_reasoning(thread_id)` when you need the human-readable trace for observability dashboards.
- If you want to plug the API into the Lovable frontend, point the frontend's `.env` entry (e.g., `VITE_API_BASE_URL`) at `http://localhost:${VITE_BACKEND_PORT}`.

### Calling the FIBO model via the API
Once the FastAPI (or any HTTP) wrapper is running, clients can trigger the loop—and, by extension, the FIBO generator—over HTTP. Example request:

```bash
curl -X POST http://localhost:8000/api/fibo/run \
  -H "Content-Type: application/json" \
  -d '{
        "prompt": "Design a hero shot for the FIBO launch page",
        "structured_prompt": {
          "mode": "generate",
          "prompt_summary": "Flagship hero shot for the FIBO brand site; mascot waving stage-left.",
          "brand": {
            "color_palette": ["#EA1E63", "#FFCA3A", "#151E3D", "#F5F5F5"],
            "gaze_direction": "stage-left"
          }
        }
      }'
```

Response (abridged):

```json
{
  "image": {
    "id": "b904c045-d4d4-4341-ae98-45a647268ca1",
    "description": "Design a hero shot for the FIBO launch page",
    "colors": ["#EA1E63", "#FFCA3A", "#151E3D", "#F5F5F5"],
    "gaze_direction": "stage-left",
    "provenance": "color_palette_lora"
  },
  "compliance": {
    "palette_ok": true,
    "gaze_ok": true,
    "issues": []
  },
  "history": [
    "FIBO agent produced a candidate image.",
    "Brand Guideline agent evaluated the candidate.",
    "FIBO agent applied the color palette LoRA.",
    "Brand Guideline agent evaluated the candidate.",
    "Compliance achieved; workflow exiting."
  ],
  "thread_id": "workflow_1737423430123"
}
```

Under the hood the `/api/fibo/run` handler calls `AgenticWorkflow.generate_from_prompt`, which orchestrates:
1. `FiboAgent.bootstrap_image` to talk to the Original FIBO generator (replace `OriginalFiboGenerator.generate` with your production FIBO API client if needed, e.g., by issuing an HTTP request with `httpx` or `requests` inside that method).
2. `BrandGuidelineAgent.evaluate` for compliance.
3. `FiboAgent.improve_image` (Color Palette LoRA) for iterative corrections.

By swapping the implementation of `OriginalFiboGenerator.generate` you control exactly how the FIBO model is invoked while the rest of the orchestration—history logging, compliance reporting, and reasoning—stays the same.

### Calling BRIA’s Structured-Prompt API
When a user uploads inspiration art, we rely on BRIA to convert that reference into a structured prompt that feeds the FIBO loop. Replace the simulated `ImageToPromptTool` with a thin HTTP wrapper that hits BRIA’s `/v2/image/structured-prompt` endpoint using the `BRIA_API_KEY` from your `.env`.

```python
import httpx
from agentic.structured_prompt import StructuredPrompt

class BriaImageToPromptTool:
    def __init__(self, api_key: str, base_url: str = "https://api.bria.ai"):
        self.client = httpx.Client(
            base_url=base_url,
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
            },
            timeout=30,
        )

    def run(self, image: ImageArtifact, base_prompt: str) -> StructuredPrompt:
        payload = {
            "mode": "inspire",
            "prompt_summary": base_prompt or image.description,
            "source_image_id": image.id,
            "image_url": image.metadata.get("url"),
            "color_palette_hint": image.colors,
            "gaze_direction": image.gaze_direction,
        }
        response = self.client.post("/v2/image/structured-prompt", json=payload)
        response.raise_for_status()
        return StructuredPrompt.from_obj(response.json())
```

Swap the default tool inside `FiboAgent`:

```python
from agentic.agents import FiboAgent

class ProductionFiboAgent(FiboAgent):
    def __init__(self, bria_api_key: str):
        super().__init__()
        self.image_to_prompt = BriaImageToPromptTool(api_key=bria_api_key)
```

Quick smoke test with curl (the `image` payload can be a URL or base64 depending on your BRIA plan):

```bash
curl -X POST https://api.bria.ai/v2/image/structured-prompt \
  -H "Authorization: Bearer $BRIA_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
        "mode": "inspire",
        "prompt_summary": "Use this backstage photo as the hero pose",
        "image_url": "https://example.com/uploads/fibo-mascot.jpg"
      }'
```

Tie it together with the FastAPI wrapper:
1. The client uploads an image to your backend.
2. `/api/fibo/run` saves the image (or URL) and passes it to `workflow.generate_from_prompt`.
3. `BriaImageToPromptTool.run` calls BRIA, whose response seeds the structured prompt.
4. The workflow hands that normalized prompt to the FIBO generator, closing the loop.

## Helpful references
- Structured prompt schema + sample payload: `backend/agentic/examples/fibo_structured_prompt.json`
- Configuration helpers: `backend/agentic/config.py`
- Reasoning/metrics utilities: `backend/agentic/utils/reasoning.py`
- Frontend entry point and Vite config: `lovable-frontend/vite.config.ts`

With these pieces in place you can iterate on the FIBO model prompts locally, in Docker, or behind an API without losing sight of the brand-guideline contract that drives the experience.
